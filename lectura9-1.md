# üìñ Critica: Multi-armed recommender system bandit ensembles.
 
### üìöIntroducci√≥n:

En este paper se propone un esquema de ensambles como parte de un sistema recomendador h√≠brido, la idea es que, a partir de varios sistemas recomendadores, se puede construir un solo sistema que optimice y encuentre la mejor combinaci√≥n para el problema de recomendaci√≥n.

Adem√°s, los autores van m√°s all√° y prueban su esquema de una forma que denominan "realista", donde se hace un proceso ciclico que busca similar la utilizaci√≥n del sistema recomendador.

En esta cr√≠tica se comentar√°n estos dos aspectos:

## üßæ M√©todo de ensamble:

En espec√≠fico, los autores presentan un *Bandit Recommender System Ensembles*, un m√©todo donde cada "brazo" es un sistema recomendador distinto. La idea b√°sica del esquema ser√° optimizar la forma en que se eligen estos brazos a la hora de hacer una recomendaci√≥n.

‚úÖ Los m√©todos de ensambles han mostrado ser super eficientes en muchas tareas de *machine learning*, por lo que extenderlo a sistemas recomendadores hace mucho sentido. A partir de esto, creo que es un gran m√©todo y que probar distintos m√©todos de ensambles puede dar muy buenos resultados en este tipo de problemas.

Adem√°s, los autores utilizan dos m√©todos de selecci√≥n para el algoritmo *e-greedy* y *Thompson method*.

‚ùå Si bien ambos m√©todos parecen ser de los m√©todos m√°s utilizados en el momento del paper, existen m√©todos (como los explorados en la segunda lectura) que muestran mejores resultados mejores o similares, como *Upper Confidence Bound* (en [1]) u otras formas de abordar el m√©todo de *Thompson* ([2]) o *e-greedy*.

## üìà Testeo Cicl√≠co:

Los autores hace el testeo de su modelo de forma "offline", pero de una forma en la cual se puede simular el uso en el tiempo del sistema recomendador. Para esto, se parte de una porci√≥n peque√±a del *dataset* total y se van generando recomendaciones y, a partir si se encuentra en el resto del dataset, se formula un *reward* postivio o negativo. Esto hace por *√©pocas*, donde en cada una se recomienda solo un *item* a cada usuario.

‚úÖ Me parece fundamental y necesaria esta forma de testear sistemas recomendadores, ya que hasta ahora, los m√©todos de testeos mostrado son malos simulando el uso real de un sistema recomendador.

Sobre el ensamble que los autores hicieron, usaron un esquema con dos sistemas de *collaborative filtering* ( **kNN** y **matrix-factorization**).

‚ùå El principal problema que encuentro es que se probaron solo dos m√©todos y en base solo a filtrado colaborativo. Esto es un problema, ya que un sistema de ensambles podr√≠a aprovechar mucho mejor la combinaci√≥n entre *content-based* y *CF*, en este sentido, creo que los autores debieron utilizar diversos m√©todos (entiendo que igual podr√≠a deberse a un problema con el *dataset* utilizado).

## üíª Resultados:

Los resultados experimentales obtenidos se muestran a continuaci√≥n:

![picture 1](images/f833d8e93dc87c1c170ae0a09c9a0d5ad7f0b08bd9dc00f8c88764cf801dc084.png)  

Desde estos podemos ver que el m√©todo que los autores proponen obtuvo mejores resultados que los "brazos" por si solos. En este sentido, el m√©todo de ensamble muestra un beneficio considerable, pero hay ciertas complicaciones que siento se deber√≠a atacar:

1. **El m√©todo de ensamble principal se mantiene constante:** La optimizaci√≥n del paper lleva a eligir casi siempre le m√©todo de *matrix-factorization*. Esto lo atribuyen a lo bueno que es este sistema, pero puede mostrar un problema del mismo esquema de optimizaci√≥n.

2. **El dataset muestra ser mejor en _most popular_:** Me parece extra√±o esto ya que generalmente *personalized recommendation* suele ser mejor que un m√©todo no personalizado, por lo que me gustar√≠a investigar si esto se debe al esquema c√≠clico probado o porque realmente para el dataset *most-popular* es mejor.

## üìé Bibliograf√≠a:

1. Auer, P., Cesa-Bianchi, N. & Fischer, P. Finite-time Analysis of the Multiarmed Bandit Problem. Machine Learning 47, 235‚Äì256 (2002). https://doi.org/10.1023/A:1013689704352

2. Chapelle, O., Li, L. (2011). An Empirical Evaluation of Thompson Sampling.