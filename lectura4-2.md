# üìñ Critica: Document Clustering Based On Non-negative Matrix Factorization
  
### üìöContexto:

Si bien este paper no est√° directamente relacionado con la implementaci√≥n de sistemas recomendadores, me parece que la idea detr√°s de _Document Clustering_ es bastante similiar a otras que ya hemos explorado en el curso (de hecho ocupa t√©cnicas similares).

El problema de **_Document Clustering_** se puede dividir en dos grandes √°reas, _agglomerative clustering_ y _partitional clustering_. Los autores basan su propuesta en este segundo grupo, que tiene como idea base descomponer los documentos en _clusters_ disjuntos y que, en la construcci√≥n de estos, se pueda llegar al √≥ptimo de una funci√≥n espec√≠fica. De forma m√°s detallada, los autores originan su propuesta desde **una idea similar a la de _Latent Semantic Indexing Method (LSI)_**, que descompone cada documento a un espacio de vectores singulares utilizando _SVD_.

## üìà Propuesta:
Seg√∫n los autores, el m√©todo de _LSI_ ten√≠a dos grandes problemas: 1. El uso de _SVD_ produce valores negativos, por lo que **no hay un real valor sem√°ntico** en cada direcci√≥n y 2. A√∫n **se requiere utilizar m√©todos de clustering tradicionales** a partir de los resultados.

As√≠, los autores proponen un modelo basado en _Non-Negative Matrix Factorization (NMF)_. La idea principal es establer un espacio vectorial donde **cada eje corresponda a un _t√≥pico_ (tipo) distinto de documento** y que, **cualquier documento se puede modelar como una combinaci√≥n lineal de estos t√≥picos**.

‚úÖ Desde esta primera vista, este m√©todo tiene el beneficio de ser bastante m√°s autoexplicativo que el m√©todo de _LSI_. De todas formas, creo que partir de la base que de _LSI_ no puede tener valor sem√°ntico por tener valores negativos es un error, ya que podr√≠a significar componentes opuestas. Creo que este punto depende m√°s de c√≥mo se define las categor√≠as en cada texto (el _embedding_ que se le hacen a las palabras de este).

üòê Una vez que su modelo descompone en sus componentes a un documento, sus valores _x<sub>i</sub>_ van a estar en el rango [0, 1] y, nn el algoritmo de los autores, se utiliza el _x<sub>i</sub>_ con mayor valor para determinar a qu√© cluster pertenece. Si bien no puedo decir que esto es negativo, ya que en un problema de _clustering_ se debe definir solo una clase, creo que en este punto hay un gran p√©rdida de informaci√≥n. Especialmente, siento que en los casos donde hay varios valores con > 0, **la informaci√≥n que da esta descomposici√≥n es bastante significativa** y, creo, que tiene harto sentido incluirla en una aplicaci√≥n de recomendaci√≥n (el punto clave de la **explicatividad de los resultados**).

Para comparar con el m√©todo de LSI, los autores presentan un ejemplo visual de sus resultados en un _dataset_ con 3 _clusters_. En la imagen se pueden ver los resultados obtenidos en cuanto a sparabilidad de la informaci√≥n y los valores en los ejes.

 ![picture 2](images/e81d7841675a08adba0a2d46a714f76f978a5d352a290b83bd21ed34266acb35.png)  


‚ùå En este punto, que es como una forma m√°s visual de ver lo que hace su modelo, me hubiera gustado ver la separaci√≥n que logra en _datasets_ que cuentan con m√°s _clusters_ (En este caso exist√≠an solo _3 clusters_). Ya que si bien es importante dar un significativo positivo a cada eje, la separabilidad de los _clusters_ es lo que prima en los rendimiento que estos obtienen y, a simple vista, no hay diferencia sustancial entre ambos modelos.

## üìà Experimentaci√≥n:

En su experimentaci√≥n los autores utilizaron dos _datasets_ distintos y compararon su modelo con dos m√©todos del estado del arte de la √©poca _Avarege Association (AA)_ y _Normalized Cut (NC)_. Adem√°s, propusieron para su m√©todo un esquema de entrenamiento que utiliza una matriz de datos con _pesos_, que es algo similiar a lo que hace el m√©todo _NC_.

‚ùå Si bien me parece correcto que hayan medido su m√©todos con estos dos esquemas, creo que hubiera sido √∫til el hecho de ver la comparaci√≥n de resultados con _LSI_. Aparte, creo que si bien 2 _datasets_ han sido sufientes en las lecturas que hemos hecho, puede ser necesario hacer m√°s _benchmarks_ de evaluaci√≥n (m√°s _datasets_).

‚úÖ Las m√©tricas que utilizaron para medir sus resultados fueron las de _accuracy_ y _mutal information_, las cuales me parecen buenas m√©tricas a la hora de evaluar clusterings. Si bien hay bastantes m√©tricas m√°s que pudieron utilizar (por ejemplo en [1]), creo que temas de _cluster quality_ y _number of clusters_ carecen de sentido ac√°, pues si bien ellos est√°n haciendo "clustering", su **esquema principal es la clasificaci√≥n de documentos** utilizando _clustering_.

Finalmente, sobre los resultados que llegaron no tengo mucho que agregar, solo no me gusta la generalizaci√≥n que hicieron:

> (...) regardless of the document corpora, the performance ranking is always in the order (...)

Ya que siento que el n√∫mero de _benchmarks_ realizados no da para hacer una afirmaci√≥n del estilo.

## üìï Conclusi√≥n:
Si bien esta lectura no se bas√≥ sobre la tem√°tica de sistemas recomendadores, creo que hay varios puntos de la formulaci√≥n hecha por los autores que se puede aplicar a un sistema recomendador. Los dos principales son la idea de esta **explicativilidad que se le da a la descomposici√≥n de textos**, la cual hemos visto es un _feature_ importante para los usuarios y, la forma de hacer **_clustering_ para la b√∫squeda de textos similares**. Pues desde estas no es descabellado pensar en utilizar el _cluster_ cercano para hacer recomendaciones o, ligado a **_content-based_ usar la descripci√≥n obtenida de la descomposici√≥n como _feature_ de un texto**.

## üñá Bibliograf√≠a Revisada:

1. Manimaran. (2019). Clustering Evaluation strategies. Recuperado de [Medium](https://towardsdatascience.com/clustering-evaluation-strategies-98a4006fcfc)
