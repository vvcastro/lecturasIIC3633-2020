# üìñ Critica: Document Clustering Based On Non-negative Matrix Factorization
  
- Latent semantic indexing method SVD.
    
- Bastante bueno para la representaci√≥n de los clusters.
  
### üìöContexto:

Si bien este paper no est√° directamente relacionado con la implementaci√≥n de sistemas recomendadores, me parece que la idea detr√°s de _Document Clustering_ es bastante similiar a otras que ya hemos explorado en el curso (de hecho ocupa t√©cnicas similares).

El problema de **_Document Clustering_** se puede dividir en dos grandes √°reas, _agglomerative clustering_ y _partitional clustering_. Los autores basan su propuesta en este segundo grupo, que tiene como idea base descomponer los documentos en _clusters_ disjuntos y que, en la construcci√≥n de estos, se pueda llegar al √≥ptimo de una funci√≥n espec√≠fica. De forma m√°s detallada, los autores originan su propuesta desde **una idea similar a la de _Latent Semantic Indexing Method (LSI)_**, que descompone cada documento a un espacio de vectores singulares utilizando _SVD_.

## üìà Propuesta:
Seg√∫n los autores, el m√©todo de _LSI_ ten√≠a dos grandes problemas: 1. El uso de _SVD_ produce valores negativos, por lo que **no hay un real valor sem√°ntico** en cada direcci√≥n y 2. A√∫n **se requiere utilizar m√©todos de clustering tradicionales** a partir de los resultados.

As√≠, los autores proponen un modelo basado en _Non-Negative Matrix Factorization (NMF)_. La idea principal es establer un espacio vectorial donde **cada eje corresponda a un _t√≥pico_ (tipo) distinto de documento** y que, **cualquier documento se puede modelar como una combinaci√≥n lineal de estos t√≥picos**.

‚úÖ Desde esta primera vista, este m√©todo tiene el beneficio de ser bastante m√°s autoexplicativo que el m√©todo de _LSI_. De todas formas, creo que partir de la base que de _LSI_ no puede tener valor sem√°ntico por tener valores negativos es un error, ya que podr√≠a significar componentes opuestas. Creo que este punto depende m√°s de c√≥mo se define las categor√≠as en cada texto (el _embedding_ que se le hacen a las palabras de este).

üòê Una vez que su modelo descompone en sus componentes a un documento, sus valores _x<sub>i</sub>_ van a estar en el rango [0, 1] y, nn el algoritmo de los autores, se utiliza el _x<sub>i</sub>_ con mayor valor para determinar a qu√© cluster pertenece. Si bien no puedo decir que esto es negativo, ya que en un problema de _clustering_ se debe definir solo una clase, creo que en este punto hay un gran p√©rdida de informaci√≥n. Especialmente, siento que en los casos donde hay varios valores con > 0, **la informaci√≥n que da esta descomposici√≥n es bastante significativa** y, creo, que tiene harto sentido incluirla en una aplicaci√≥n de recomendaci√≥n (el punto clave de la **explicatividad de los resultados**).

Para comparar con el m√©todo de LSI, los autores presentan un ejemplo visual de sus resultados en un _dataset_ con 3 _clusters_. En la imagen se pueden ver los resultados obtenidos en cuanto a sparabilidad de la informaci√≥n y los valores en los ejes.

 ![picture 2](images/e81d7841675a08adba0a2d46a714f76f978a5d352a290b83bd21ed34266acb35.png)  


‚ùå En este punto, que es como una forma m√°s visual de ver lo que hace su modelo, me hubiera gustado ver la separaci√≥n que logra en _datasets_ que cuentan con m√°s _clusters_ (En este caso exist√≠an solo _3 clusters_). Ya que si bien es importante dar un significativo positivo a cada eje, la separabilidad de los _clusters_ es lo que prima en los rendimiento que estos obtienen y, a simple vista, no hay diferencia sustancial entre ambos modelos.

### üìà Recommender System Properties

### üìï Conclusi√≥n:

## üñá Bibliograf√≠a Revisada:

