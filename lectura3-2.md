# üìñ Critica: Evaluating Recommender Systems, Recommender Systems Handbook

### üìöContexto:
Esta lectura fue un poco distinta al resto ya que pertenecia a un libro y, por lo tanto, no estaba escrito con la idea de revelar nuevos hallazgos o indicar experimentaci√≥n realizadas.

Dicho esto, el cap√≠tulo se centra en las distintas metodolog√≠as y m√©tricas que se tienen para evaluar los sistemas recomendadores actuales (~2010). Para esto los autores se√±alan dos principales ejes en los cuales se centra su contenidos: **_Experimental Settings_** y **_Recommender System Properties_**:

### üß™ Experimental Settings:

Esta secci√≥n explora las principales m√©todolog√≠as y herramientas estad√≠sticas que se pueden utilizar a la hora de hacer experimentos con sistemas recomendadores. En primera instancia, se definen tres esquemas que permiten evaluar caracter√≠sticas de estos sistemas: **_Offline Experiments_**, **_User Studies_** y **_Online Evaluation_**.

1. **_Offline Experiments_**: Todos los papers que hemos analizado hasta ahora siguen este tipo de evaluaci√≥n. En esta secci√≥n me gust√≥ la idea de que incluir los _timestamps_ en la formulaci√≥n del _dataset_ y el testeo sobre este. Para mi esto fue interesante, pues, si bien casi todos los papers que he visto siguen este m√©todo, pocas veces se ocupa se utilizan todas las ideas que se proponen (en cuanto a la simulaci√≥n del comportamiento de los usuarios) .

2. **_User Studies_**: Este punto se basa en utilizar grupos de usuarios para testear distintos recomendadores y, como las distintas formas de conseguirlos puede introducir _bias_ en nuestro experimento. Para mi, esta secci√≥n me result√≥ sumamente interesante, ya que permit√≠a hacer un puente con temas relacionados a la psicolog√≠a de los usuarios.

3. **_Online Evaluation_**: B√°sicamente, es la idea de hacer experimentaci√≥n y evaluaci√≥n "en  vivo". Ac√° el usuario utiliza la plataforma real donde el sistema se va a implementar. Si bien esto tiene el beneficio de que el usuario no se da cuenta que se est√° ocupando para el experimento (lo cual sirve para disminuir _bias_), el hecho de estar "probando" recomendadores pueden disminuir el uso de la p√°gina.

‚úÖ Un tema que me gust√≥ y descubr√≠ en esta lectura, es que estos m√©todos no son excluyentes y muchas veces para implementar un sistema recomendador es necesario pasar por todos estos pasos antes de poder tomar decisiones.

‚ùå Creo que, siendo que ac√° se abordan temas desde la interdisciplina (con _marketing_ o _psicolog√≠a_), hay aspectos que quiz√°s no fueron tan bien profundizados (de todas formas, se entiende que este no era el fuerte del texto).

Finalmente, esta secci√≥n termina con los m√©todos estad√≠sticos que se utilizan para determinar si un experimento fue significativo y si los resultados fueron o no concluyentes. En espec√≠fico se exploran m√©todos de inferencia como _p value_, intervalos de confianza, etc.

‚úÖ Para mi esto es bastante significativo, ya que si bien son _tests_ que sab√≠a que exist√≠an, en ning√∫n paper relacionado (de los que he le√≠do para el ramo) he visto que han introducido este tipo de estad√≠stica para justificar los experimentos.

### üìà Recommender System Properties

En este punto se exploran (creo) todas las m√©tricas que hoy se utilizan para evaluar sistemas recomendadores. Y, si bien, creo que existen m√©tricas m√°s significativas que otras (por lo menos cuando estamos buscando mejores recomendaciones), el hecho de que **se hable de un _trade-off_** entre estas me parece relevante y algo a considerar siempre que se implementen estos sistemas.

Por otra parte, creo que es importante destacar que el texto da ejemplos de c√≥mo estas distintas m√©tricas pueden afectar la visi√≥n que los clientes tienen sobre el sistema. Y, si bien hay m√©tricas como **_Privacy_** que, a√∫n siendo dificiles de calcular desde un punto de vista de programaci√≥n, deben ser consideradas como "utilidad" para los usuarios.

 Finalmente, creo que una de las m√©tricas que m√°s me gust√≥ es la de _utility_, pues siento que sirve como una herramientas de generalizaci√≥n bastante fuerte frente a problemas reales (especialmente el hecho de poder dar utilidad negativa a resultados no deseados).

### üìï Conclusi√≥n:

Creo que este cap√≠tulo y, especialmente, la secci√≥n de las m√©tricas, abren el espacio para poder entender que un sistema recomendador no solo se base en mejorar predicciones. Es importante entender como cada decisi√≥n que se toma sobre la implementaci√≥n que estamos haciendo puede afectar positiva o negativamente como resulta nuestro experimento o lo que el usuario est√° recibiendo de nosotros (la idea del _tradeoff_)

## üñá Bibliograf√≠a Revisada:

1. Anna B. (2016). Recommender Systems - It's Not All About the Accuracy. Recuperado de [Medium](https://gab41.lab41.org/recommender-systems-its-not-all-about-the-accuracy-562c7dceeaff).
