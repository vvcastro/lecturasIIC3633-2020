# 游닀 Critica: Item-based collaborative filtering recommendation algorithms...

### 游닄Contexto:
Los algoritmos que utilizan _Collaborative Filtering (CF)_ son m칠todos de recomendaci칩n que se basan en buscar similitudes entres usuarios o _items_ y, a partir de estas generar recomendaciones. Estos algoritmos se pueden dividir en _memory-based methods_ y _model-base methods_, entre los primeros se encuentran los _user-based_ e _item-based_ que ser치n los principales puntos de discusi칩n en el art칤culo.

Si bien algoritmos que emplean _CF_ y, espec칤ficamente, _user-based CF_ son los algoritmos m치s populares y utilizados en la pr치ctica (en los a침os del paper), la expansi칩n de las aplicaciones _web_ y los millones de nuevos datos que estas generan ha revelado problemas espec칤ficos en estos cuando se habla de **escalabilidad** o la **distribuci칩n datos**.

### 游 Item-Based CF:
Ante estas problem치ticas, los autores proponen un esquema _item-based CF_ que ataca ambos problemas y que, seg칰n los experimentos realizados, resulta en un menor tiempo de computo y mejores rendimientos. Se discutir치 qu칠 aspectos del esquema propuesto ayudan a mitigar o mejorar estos problemas:

La cualidad que parece m치s relevante en el esquema es la idea de poder calcular similitudes con anterioridad y, a partir de estas, hacer **_prunning_** para disminuir la carga posterior del procesamiento. Y, si bien en el paper se propone un m칠todo que termina con _top-k_ vecinos:

> For each item _j_ we compute the _k_ most similar items, where _k_ << _n_ and record these item numbers and their similarities with _j_

Existen otras t칠cnicas interesantes que se podr칤an agregar en el 치rticulo, como hacer _prunning_ dejando _items_ que tengan un m칤nimo de _m_ evaluciones de usuarios en com칰n.

Esta l칩gica es la clave de **escalabilidad** presentada en el paper, pues al agregar nuevos usuarios se puede asumir que la similitud entre _items_ tiene variaciones peque침as o incluso despreciables. Adem치s, esta misma es capaz de atacar el problema de reducci칩n de rendimiento  en los casos donde la **distribuci칩n de datos** es pobre (ie: usuarios nuevos que no tienen muchos _ratings_), pues el recomendador se basar치 en los _items_ en los que s칤 se han hecho evaluaciones, lo que definitiva mejorar치 la predicci칩n para estos usuarios.

### 游눹 Experimentaci칩n:
El experimento que se realiza en el paper se basa en un _dataset_ de evaluaci칩n de pel칤culas con 43.000 usuarios y m치s de 3.500 pel칤culas, de los cuales se seleccion칩 al azar para obtener exactamente ```100.000 ratings```. Estos datos definieron un **sparcity level** de 0.9369 el cu치l no se vari칩 en ning칰n experimento.

Para m칤 este es el fue el primer punto en contra en sus experimentos, pues creo que ser칤a necesario hacer un an치lisis de sensibilidad sobre esta variable, pues tampoco hay una justificaci칩n para esta elecci칩n (como por ejemplo, que estos sean los valores observados en las aplicaciones comerciales). En vez de esto se elige variar la porci칩n de datos en _training/testings sets_.

A partir de este _dataset_ se elige la m칠trica _MAE_ para la comparaci칩n de rendimientos de diferentes esquemas. Esto genera 




## 游둖 Referencias:

1. Schafer, J. B., Frankowski, D., Herlocker, J., & Sen, S. (2007). Collaborative filtering recommender systems. In The adaptive web (pp. 291-324). Springer Berlin Heidelberg.

2. Ricci, F., Rockach L., Shapira B. (2010). A Comprehensive Survey of Neighborhood-Based Recommendation Methods. Recommender Systems Handbook (pp. 37-76) 
