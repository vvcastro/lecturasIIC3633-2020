# üìñ Critica: A user-centric evaluation framework for recommender systems.
 
### üìöIntroducci√≥n:


Hasta la √©poca cercana al paper (~2010), la mayor√≠a de los estudios en sistemas recomendadores se hab√≠an basado en la idea de que un mejor sistema recomendador era el que perfeccionaba m√©ticas como *Accuracy*, *Precision*, *nDCG*, etc. Sin embargo, el uso y perduraci√≥n en el tiempo de estos sistemas est√° fuertemente ligado a la percepci√≥n que los usuarios tienen de este, la cual no siempre est√° bien promovida por mejores *accuracies*. En este sentido, este art√≠culo explora y profundiza la idea de hacer evaluaciones en base a la **_Experiencia del usuario_**, lo cual, si bien lleva a hacer una evaluaci√≥n m√°s cualitativa del funcionamiento del recomendador, generar estad√≠sticas importantes y que deben ser analizadas a la hora de implementar un Sistema Recomendador. 

### üßæ ResQue:

Con esto en mente, los autores presentan un *framework* basado en un cuestionario (**ResQue**) para someter a evaluaci√≥n y medir, desde la subjetividad de los usuarios, la satisfacci√≥n que tienen sobre un sistema recomendador.

 El esquema que proponen se divide en 4 *construcs* principales: **_User Perceived Qualities_**, **_User Beliefs_**, **_User Attitudes_** y **_Behavioral Intentions_**. A su vez, cada uno de estos *constructs* tiene subdivisiones que finalmente conforman 13 componentes distintos del esquema.

 ‚ùå Creo que la principal cr√≠tica que se le puede hacer a la publicaci√≥n es el hecho de que, si bien presentan el esquema, no hay ningun resultados de su aplicaci√≥n (hay resultados de esquemas similares en el pasado). Esto es un problema, ya que, sobre todo al necesitar directamente interacci√≥n con usuarios, la puesta en marcha del m√©todo puede generar problem√°ticas no vistas en la formulaci√≥n te√≥rica.

## üìà Contrucs:

En este apartado se analizar√° cada uno de los componentes principales presentados en el *framwork*:

1. **Perceived System Qualities:** Referido al funcionamiento como tal del sistema recomendador, **busca cuantificar las m√©tricas que generalmente se estudian de manera *offline*** (*accuracy*, *diverse*, *context compatible*, etc), desde la experiencia e interacci√≥n con el usuario. Adem√°s, se incluye la evaluaci√≥n de la interfaz que se le expone al usuario (c√≥mo se exponen las recomendaciones).

    ‚úÖ Creo que este primer apartado logra bien su objetivo ya que presenta ideas que no se han estudiado hasta ahora, como *relative accuracy*, respecto a recomendaciones de amigos. Adem√°s, creo que varias de las m√©tricas como *Novelty* y *Diversity* son mucho m√°s significativas si son evaluadas desde el punto de vista del usuario (que es lo que se hace en este apartado).

    ‚ùå Como punto en contra, creo que alguna de las preguntas que se plantean pueden ser algo ambiguas (lo que puede suponer respuestas no tan representativas):

    ><ul>
    ><li>The items recommeded to me are attractive. </li>
    ><li>I enjoyed the items recommended to me.</li>
    ></ul>

2. **User Beliefs:** Esta m√°s orientado a c√≥mo se siente el usuario al ser recomendado/usar el Sistema (se explica como algo m√°s del momento). En este sentido, se eval√∫an la idea de *Ease of Use* (la habilidad del usuario para resolver tareas de buena manera), *Perceived Usefulness* (la sensaci√≥n del usuario sobre si usar el sistema mejor√≥ su rendimiento) y *Control and Trasparency* (si el usuario siente control sobre sus recomendaciones y si estas se pueden explicar de buena manera).

    ‚úÖ Creo que este apartado es bastante bueno y significativo, en el sentido que explora ideas significativas del uso de un sistema recomendador. Por ejemplo, ellos dicen que 
    
    > (...) perceived ease of use may be more appropiate than using the objective task completion time (...)
    
    Lo cual presenta una buena ventaja comparativa y diferenciaci√≥n respecto a otros esquemas estudiados (me gusta porque lo presenta como una actividad m√°s real). En este sentido, creo que las decisiones tomadas en este apartado est√°n bien justificadas y pueden un impacto positivo y significativo en la implementaci√≥n de estos modelos de testeo.

3. **User Attitudes:** Es similar al concepto de *Beliefs*, pero, seg√∫n el paper, estos perduran m√°s en el usuario. Se ven m√©tricas de *Overall Satisfaction*, *Confidence Inspiring* y *Trust*.

4. **Behavioral Intentions:** Orientado a si el sistema es capaz de influenciar al usuario para usar o recomendar el sistema en un futuro.

    ‚ùå Siento que estos dos √∫ltimos puntos se analizan con poca profundidad en el *paper*, siendo que, creo, est√°n bastante relacionados y tienen gran relevancia en la perduraci√≥n y √©xito de un sistema recomendador. Sobre todo para estos puntos creo que hubiera sido fundamental ver resultados experimentales, ya que, por ejemplo, un usuario puede hablar sobre recomendar la aplicaci√≥n en el momento que se le pregunta, pero no llegar realmente a hacerlo (creo que esto se mezcla un poco con la psicolog√≠a en este tipo de estudios). En este sentido, creo que f√°cilmente estos dos aparatados pueden caer al ser analizados con resultados reales.

### üìï Simplified Model:

En la √∫ltima secci√≥n del paper se propone un modelo simplificado de este esquema, en base a la idea de que estas ```60 preguntas``` pueden ser complejas de aplicar en una evaluaci√≥n normal.

‚ùå Creo que si bien hay un punto en el n√∫mero de preguntas que se aplican, siento que sin una experimentaci√≥n real es muy complicado efectivamente decir si este modelo simplificado obtiene buenos resultados (o incluso el modelo que proponen). En este sentido, creo que lo correcto hubiera sido hacer una comparativa con resultados sobre la inferencia que se puede hacer desde ambos modelos.

## üíª Conclusiones:

Creo que este *paper* sienta bases importantes para la medici√≥n de la experiencia del usuario de un sistema recomendador. Este es un elemento bastante significativo en la implementaci√≥n de muchas aplicaciones de uso comercial (tambi√©n de no comerciales) donde la interacci√≥n con el usuario debe ser la mejor posible y donde, en pos de captar la atenci√≥n de usuarios, m√©tricas como *perceived ease of use* pueden tomar relevacia frente a m√©tricas tradionales de *accuracy*.

## üñá Bibliograf√≠a Revisada: