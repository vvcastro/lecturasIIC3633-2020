# üìñ Critica: Post FunkSVD...

### üìöContexto:
En 2006 Netflix inici√≥ el concurso de NetflixPrize el que ten√≠a como tarea ensamblar el mejor algoritmo de _Collaborative Filtering (CF)_ para un sistema recomendador basado en los datos de la propia plataforma. El blog/post presentado cuenta el desarrollo y la l√≥gica que sigui√≥ _Simon Funk_ para terminar en el tercer lugar de dicha competencia.

### üßæ FunkSVD:

_Funk_ bas√≥ su propuesta en un algoritmo SVD (_Single Value Decomposition_) el cual pertenece a la rama de _model-based CF_, es decir, tiene como objetivo generalizar los datos en un modelo que contabilice "caracter√≠sticas" (en este caso _latent factors_) tanto de los usuarios como de las pel√≠culas. Adem√°s, este m√©todo realiza _Matrix Factorization (MF)_, que es la idea de reducir la matriz principal de ```user/movies``` en dos matrices con dimensiones m√°s peque√±as (con el n√∫mero de usuarios/pel√≠culas vs los _latent factors_).

El gran problema que generaba el _dataset_ entregado por _Netflix_ era la **sparcity** de los datos (hab√≠an muchas casillas nulas en la matriz). Lo que √©l hizo fue ignorar est√°s casillas sin datos y centrarse en aprender desde los datos que ten√≠a. Para esto, como cualquier modelo de _machine learning_ al calculaba el error de su predicci√≥n y reajustaba estos _latent factors_ seg√∫n estos errores (en otras palabras hacia un _gradient descent_). De todas formas, explora m√©todos para obtener informaci√≥n relevante sobre estas casillas nulas (determina de que se pod√≠an estimar con una distribuci√≥n _Gaussiana_).

### üíª Aspectos interesantes:
Creo que una de las propiedades m√°s importante de su modelo es la **gran escabilidad** que alcanza (esto dado que es un _MF method_). De hecho, para los _latent factors_ definidos en su experimentaci√≥n (40) el logr√≥ un factor de reducci√≥n de alrededor de x400, lo que produce un disminuci√≥n en tiempo de ejecuci√≥n bastante significativa.

Otro punto que me parece necesario recalcar es que su algoritmo **no se ve afectado por el problema de _local minima_** presentes en otros problemas de optimizaci√≥n. Esto se (puede deber) debe a que la funci√≥n de p√©rdida que _FunkSVD_ busca minimizar es convexa lo que nos asegura poder llegar a un √≥ptimo. De todas formas, esto trae el problema de _overfitting_ que tambi√©n se describe en el post.

### üìï Aspectos (no tan) en contra:
Si bien existe el problema de que muchas de sus decisiones no fueron justificadas ya sea matem√°ticamente o experimentalmente, puedo asumir que esto se debe a que el blog no es un medio cient√≠fico formal. As√≠ que, pasando esto por alto, hay un par de aspectos en lo que creo pudo haber mejorado:

1. Si bien es algo que viene desde la m√©trica definida por (principalmente) _Netflix_ para evaluar sus predicciones, creo que el hecho de haber **escogido solo la m√©trica de _MSE_ (_mean squared error_)** puede ser contraproducente porque esta (la m√©trica) recae directamente en lo que significan las recomendaciones que genera el algoritmo y, en este caso, lo √∫nico que se busca es minimizar este error en _rating_, lo que podr√≠a generar problemas de "sobre-especializaci√≥n" hacia pel√≠culas muy similares a las que el usuario ya conoce (lo que es un problema de **serendipity**).\
Este fen√≥meno me resulta interesante ya que cambiar la m√©trica de error con la que se aprende **podr√≠a** significar recomendaciones, por ejemplo, que sean muy distintas a lo que generalmente se ve, pero a√∫n as√≠ le gusten mucho al usuario.
   
2. Otro punto importante, en el cu√°l este esquema decae un poco es en la **incorporaci√≥n de un _bias_ por usuario**, es decir, qu√© pasa con los usuarios que tienden a ser "m√°s exigentes" y dan calificaciones menores (o mayores). Este punto es abordado por la _Biased Matrix Factorization Recommendation_ en [2], donde se decide incluir el _bias_ que tiene cada usuario y pel√≠cula, llegando a resultados mejores que sin incluirlos.
   
3. Por √∫ltimo, el mismo autor se√±ala que a la hora de tratar de **agregar informaci√≥n extra** (fecha) los rendimientos no se mantuvieron. Este problema se ha estudiado desde dos puntos, est√° la idea de c√≥mo incluir informaci√≥n impl√≠cita en el modelo (de ac√° sale **SVD++**) y la forma en la que se puede incluir la **variable de tiempo** (dado el hecho de que, por ejemplo, las pel√≠culas suelen tener un _peak_ de popularidad). Ambas tem√°ticas son desarrolladas en [3] donde, adem√°s, bajo an√°lisis experimental, se logr√° ver mejores resultados en el **modelo ```TimeSVD++```** que incorpora la idea de SVD++ y la inclusi√≥n del tiempo en el modelo.

## üñá Referencias:

1. Post de [medium](https://medium.com/datadriveninvestor/how-funk-singular-value-decomposition-algorithm-work-in-recommendation-engines-36f2fbf62cac) donde se discute sobre c√≥mo funciona FunkSVD.

2. Sun W., Zhang X., Liang W., He Z. (2015) High Dimensional Explicit Feature Biased Matrix Factorization Recommendation. In: Li XL., Cao T., Lim EP., Zhou ZH., Ho TB., Cheung D. (eds) Trends and Applications in Knowledge Discovery and Data Mining. Lecture Notes in Computer Science, vol 9441.

3. Ricci, F., Rockach L., Shapira B. (2010). Advances in collaborative filtering. Recommender Systems Handbook (pp. 83-91).